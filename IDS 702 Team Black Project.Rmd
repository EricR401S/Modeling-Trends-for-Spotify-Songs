---
title: "IDS 702 Team Black Project"
author: "Emma Wang, Pragya Raghuvanshi, Lorna Aine, Eric Rios Soderman"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Load Libraries
library(ggplot2)
library(psych)
library(corrplot)
library(dplyr)
library(table1)
library(boot)
```

```{r subset, echo = FALSE, message=FALSE, results = FALSE}
#read original data set
df <- read.csv("https://github.com/EricR401S/Modeling-Trends-for-Spotify-Songs/raw/main/archive/tracks.csv")
```

```{r datacleaning, echo = FALSE, message=FALSE, results = FALSE }
#Two columns of interest : Name of artist (if one wanted to highlight certain summary statistics), duration conversion (get minutes), the rest is perfect on its own. 

# Confirming the data types of the columns
sapply(df, class)

# Removing the brackets from the names of the artists
# This will facilitate summary statistics

df$artists<-gsub("]","",as.character(df$artists))
df$artists<-gsub("^.","",as.character(df$artists))

# New minute variable for our own use to simplify interpretation

df$duration_minutes <- df$duration_ms/(1000*60)


# Confirming that there are no missing data, except the artist name column

colSums(is.na(df))

# change "explicit" into binary factor
df$explicit_fac <- factor(df$explicit,
                         levels=c(0,1),
                         labels=c('Non-Explicit','Explicit'))

# make Date readable to R
# Emma and Eric need to revise this together, some records with Dates passed as NAs in R after running this code.
# That's the theory. It was single year dates.
df$release_year <- substr(df$release_date, 1, 4)
df$release_year <- as.integer(df$release_year)

#df$release_date <- as.Date(df$release_date, "%Y-%m-%d")

# According to variable definitions, speechiness levels above 0.66 are speech tracks such as podcasts and poetries.
# They will be removed.


df0 <- df[df$speechiness <= 0.66,]
nrow(df) - nrow(df0) #22,598 records of speech tracks

# Examining records with a value of 0 for tempo
# A total of 328 records with 0 tempo were found, and most were tracks of rain sounds and introductions. 
# Some were, unfortunately, real songs.

sum(df0$tempo==0)

# 148 of those records are from the 2010s decade, our area of interest. 
tempo_0_subset <- df0[df0$tempo == 0,]
tempo_0_subset_2010s <- tempo_0_subset[grep('201[0-9].*', tempo_0_subset$release_date),]
nrow(tempo_0_subset_2010s)

# Removing records with a value of 0 for tempo

df0 <- df0[df0$tempo != 0,]


```

```{r, echo = FALSE, message=FALSE, results = FALSE }
#subset data
subset <- df0[grepl('201[0-9].*', df0$release_year),]

#subset <- df0[grep('2010.*', df$release_date),]
```

## EXPLORING POPULARITY AND EXPLICITY OF 2010s MUSIC THROUGH MUSICALITY.

### I. Data Overview 

The data set used in this research is a subset of a larger [spotify dataset](https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks) that contained `r format(nrow(df), big.mark = ",")` tracks. Our final subset of the data set of interest to our research problems contains `r format(nrow(subset), big.mark = ",")` of observations/ tracks and `r ncol(subset)` of variables for songs between 2010 and 2019.
Our focus in this research is to infer which features of music are best associated to the popularity of songs and to predict if a song will be explicit or not based on these features. 

```{r, results = "asis", message=FALSE, warning=FALSE, echo=FALSE,results='hide'}
library(stargazer)
#generating dimensions
stargazer(dim(df), type = 'latex', header=FALSE, digits=2, title="Dimensions")
```

For the former, we were profoundly intrigued by what song features or musical attributes effectively gauge and predict a song's popularity. For the latter, we focus on validating what features of a song best predict if it is likely to be explicit or non-explicit. Explicitness refers to the use of slurs and inappropriate words in a song.

Our Research Questions:
<ul>
-What are the musical attributes that gauged the popularity of songs in the 2010s? 
*Dependent Variable (continuous) = popularity;*
*Independent Variables = acousticness, danceability, energy, instrumentation, tempo, loudness, and speechiness* 
 
-To what extent can the musicality of a song predict whether a song will be explicit or non-explicit? 
*Dependent Variable (categorical) = Explicitness;*
*Independent Variables = danceability, energy, speechiness, and tempo* 
<ul>

### II.Primary relationship of interest

To better understand the various variables that gauge the musicality of a song, we define the main variables of interest, which were sourced from Spotify's API documentation.

<ul>
-**Popularity** is calculated by an algorithm that is based on how many times a track has been played and how recent those plays were. This is the response variable of interest for research question 1 (Spotify, 2022).

-**Explicitness** is whether a song contains inappropriate words such as curse words and sexually explicit content that are unacceptable to play in some public settings. 1 is the value identifying a song as explicit, while 0 implies that a song is non-explicit. This is the dependent variable for the second research question (Spotify, 2022).

-**Acousticness** is a confidence measure from 0.0 to 1.0 of how much of the track is composed with acoustic instruments. 1.0 represents high confidence that the track is acoustic (Spotify, 2022).

-**Danceability** is a rating of a track's suitability for dancing. This metric is based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable (Spotify, 2022).

-**Energy** is a perceptual measure of intensity and activity. Energetic tracks typically feel fast, loud, and noisy (Spotify, 2022).

-**Instrumentalness** pertains to whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumentals in this context, while Rap or spoken word tracks are considered "vocal". If the instrumentalness values is greater than or equal to 0.5, the track is very likely to have no vocal content (Spotify, 2022).

-**Tempo** refers to the overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, which derives directly from the average beat duration (Spotify, 2022).

-**Loudness** measures the overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological association of physical strength (amplitude). The values typically range between -60 and 0 db (Spotify, 2022).

-**Speechiness** detects the presence of spoken words in a track. The more speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attributed value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks (Spotify, 2022).

<ul>

**Justification for Variable Selection**

First and foremost, we chose the variables for our research questions based on prior, domain knowledge of music. For the first research question, which concerns the features that popularized songs during the 2010s, a series of aforementioned predictors were chosen. What will follow is the justification for this "a priori" selection for both research questions.

Choosing the specific predictors to predict song popularity is due to the weight of their importance for the research question 1. Popular songs, whether they are an emotional ballad or a dance track, all have certain features to keep the listeners engaged and interested to repeat listening to these tracks (Leviatan, 2017). The tempo, energy and loudness indicate the pacing and sonic impact and pleasantness of the track. The speechiness, danceability and instrumentation (which also includes acoustic choices or "acousticness") dictate melody choices, chord progressions, instrument choices, wordings, vocal lines and more types sonic layers. However, the latter is very nuanced because it pertains to the genre choice of the producers. There are very popular songs with high instrumentation, no words and low danceability, such as songs from classical music. On the other hand, Pop and Rock songs vary their levels of instrumentation and acousticness and speechiness. Lastly, if the song is aimed towards a festive audience, such as a club song, then prioritizing danceability governs the levels of instrumentation and speechiness and lack of acousticness, and this prioritization varies by genre (Androids, 2017). In conclusion, the interplay of these factors influences the popularity of songs by making them memorable and enticing. 

As for the second research question, the explicitness of tracks is strongly swayed by other factors. A very logical approach to predicting explicitness was first looking at the high levels of speechiness in songs. For example, rap songs rank high in this metric because the verses are composed of a spoken word format over a series of 8 or 16 bars, and each bar is a rap line (Edwords), while singing doesn't have to adhere to the "1 bar = 1 line" rule; thus, speechiness became the metric of most importance. In addition, songs in this genre tend to include explicit content, often sexual, in the lyrics (Tayag, 2017). Second to this metric, the other predictors of danceability, energy and tempo were considered as helpful in predicting explicitness. The energy and danceability of the song collude with speechiness to infer if a track could have explicit language. For example, a song with low energy and low danceability may or may not be less likely to have explicit language than a song with high energy and danceability, holding the speechiness level constant, and this is a relationship we wish to investigate as well. As for tempo, music genres that are known to include explicit language follow specific tempos. For instance, Trap songs usually have a tempo of 140 bpm (Burchell, 2019).

To fully understand the data with which we are working, we will explore the basic statistics of the variables of interest. 

```{r , echo=FALSE,results="asis", header=FALSE, message=FALSE, warning=FALSE }

table1(~ acousticness+danceability+energy+instrumentalness+tempo+loudness+speechiness+popularity| explicit_fac, data=subset, flip_data=TRUE, overall = "total")
```

From the table above, we can observe the mean, median, standard deviation, minimum and maximum values of variables categorized by explicit and non explicit. While mean values of acousticness, instrumentalness, tempo are higher for non explicit songs, values for energy, danceability, loudness and speechiness are higher for explicit songs. In addition, we can also infer that popularity of explicit songs is minutely higher than non explicit songs. As for standard deviation, high values for tempo and popularity indicate that the data points are spread out in relation to the mean value, whereas low values for danceability, energy, speechiness indicate that the data points are clustered around the mean. Lastly, nearly equal values of median and mean for danceability, energy and tempo indicate that the data points are more or less evenly distributed.

One way to ascertain the weight of association amongst predictors is to create a correlation matrix (See Appendix), where each variable's relationship to one another is quantified. Based on the results, except one case, the variables are weakly correlated with each other. On the other hand, the one exception was acousticness and energy, which had a fairly strong correlation that we will consider cautiously when we approach the modeling phase. 

```{r , echo=FALSE,results="asis", header=FALSE, message=FALSE, warning=FALSE}
RQ1_relation <- c("popularity", "acousticness", "danceability", "energy", "instrumentalness", "tempo", "loudness", "speechiness")
df1 = subset[RQ1_relation]
RQ2_relation <- c("explicit_fac", "danceability", "energy", "speechiness","tempo")
df2 = subset[RQ2_relation]
```

**Analysis of Variables**

**Exploratory Analysis for Research Question 1**

To better understand the data set, the popularity variable was binned into 5 groups ranging from least popular to more popular across group 1 to group 5 (See Appendix : Table of Popularity Grouping).

```{r, echo = FALSE, message=FALSE, results = FALSE }
#create datasets for EDA
#5 pop grpups across the data for better grouping
edadf1<- df1%>%mutate(popularity_fac= case_when(popularity <= 20 ~ "pop group 1",
                                                popularity <= 40 ~ "pop group 2",
                                                popularity <= 60~ "pop group 3",
                                                popularity <= 80~ "pop group 4",
                                                popularity <= 100 ~ "pop group 5"))

#eda dataset for 2: includes release year
q2 <- c("explicit_fac", "danceability", "energy", "speechiness","tempo", "release_year")
edadf2 = subset[q2]

```

```{r echo=FALSE, message = FALSE, out.width = "50%", results = "hide", fig.show='hold'}
#Relationship between danceability and popularity
ggplot(edadf1) +
  aes(x = "", y = danceability, colour = popularity_fac) +
  geom_boxplot(fill = "#112446") +
  scale_color_hue(direction = 1) +
  labs(
    x = "Popularity",
    y = "Danceability",
    title = "Relationship between danceability and popularity",
    color = "Popularity Groups",
    caption = "Fig 1"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5))

#Relationship between Instrumentalness and energy along the popularity scale
ggplot(edadf1) +
  aes(x = instrumentalness, y = energy) +
  geom_point(shape = "circle", size = 1.5, colour = "#F8766D") +
  labs(
    x = "Instrumentalness",
    y = "Energy",
    title = "Instrumentalness and Energy along the popularity scale",
    caption = "Fig 2"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5)) +
  facet_wrap(vars(popularity_fac))
```

In Figure 1, we observe that more popular songs have a higher average danceability than less popular songs. 
In Figure 2, we observe that, as songs become more popular, the energy remains evenly distributed, but the instrumentalness is reduced with the exception of a few outliers, although the relationship between the two variables becomes insignificant.

```{r echo=FALSE, message = FALSE, out.width = "50%", results = "hide", fig.show='hold'}
#Relationship between loudness and tempo along the popularity scale
ggplot(edadf1) +
  aes(x = loudness, y = tempo) +
  geom_point(shape = "circle", size = 1.5, colour = "#00BA38") +
  labs(
    x = "loudness",
    y = "tempo",
    title = "Loudness and Tempo along the popularity scale",
    caption = "Fig 3"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5)) +
  facet_wrap(vars(popularity_fac))

#Relationship between speechiness and instrumentalness along the popularity scale
ggplot(edadf1) +
  aes(x = speechiness, y = instrumentalness) +
  geom_point(shape = "circle", size = 1.5, colour = "#619CFF") +
  labs(
    x = "speechiness",
    y = "instrumentalness",
    title = "Speechiness and Instrumentalness along the popularity scale",
    caption = "Fig 4"
  )+
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5)) +
  facet_wrap(vars(popularity_fac))

```

For Figure 3, the relationship between tempo and loudness reveals a very specific recipe for the most popular songs. This group's tempo lies between 50-200 BPM (beats per minute) and -20 to 0 db, while other groups' tempo and loudness profiles remain spread out across the axes of tempo and loudness. Similarly, for Figure 4, although the speechiness values remain evenly distributed, the most popular songs exhibit a massive reduction in values in instrumentation.

Overall, the insights show that there seems to be an assortment of musical attributes that define an extremely popular song, yet they seem to be less pronounced for the less popular groups of songs. In other words, the most popular song profiles demonstrate an absence of instrumentalness and a specific range of tempo and loudness values.

**Exploratory Data Analysis for Research Question 2**

For Figure 5, it is clear that the explicit content in music has risen over the past decade. As for Figure 6, the energy in explicit songs is centered around a mean of 0.680, while the non explicit songs are skewed to a higher energy metric. In terms of Figure 7, the danceability of songs are centered around the mean of 0.687 for explicit songs and 0.599 for non-explicit songs. As for Figure 8, on average, explicit songs are less speechy than non-explicit songs. In conclusion, the chosen variables would give us a great classification of explicit and non explicit songs moving forward. 

```{r echo=FALSE, message = FALSE, out.width = "50%", results = "hide", figures-side, fig.show='hold'}
#explicity over the years
ggplot(edadf2) +
  aes(x = release_year, colour = explicit_fac) +
  geom_density(adjust = 1L, fill = "#112446") +
  scale_color_manual(
    values = c(`Non-Explicit` = "#440154",
    Explicit = "#FDE725")
  ) +
  labs(
    title = "Explicit and non explicit content in music over the years",
    x = "Release year",
    y = "Density of explicit content in music ",
    caption = "Fig 5"
  )+
  scale_x_continuous(breaks=seq(2010,2019,1))+
  theme_minimal()+
  theme(plot.title = element_text(face = "bold", hjust = 0.5))

#energy in explicit music
ggplot(edadf2) +
  aes(x = energy, colour = explicit_fac) +
  geom_histogram(bins = 30L, fill = "#112446") +
  scale_color_manual(
    values = c(`Non-Explicit` = "#440154",
    Explicit = "#FDE725")
  ) +
  labs(
    title = "Energy in explicit and non explicit songs",
    caption = "Fig 6")+
  theme_minimal()+
  theme(plot.title = element_text(face = "bold", hjust = 0.5))

#danceability in explicit music
ggplot(edadf2) +
  aes(x = danceability, fill = explicit_fac) +
  geom_histogram(bins = 30L) +
  scale_fill_manual(
    values = c(`Non-Explicit` = "#440154",
    Explicit = "#FDE725")
  ) +
  labs(
    title = "Danceability in explicit and non explicit songs",
    caption = "Fig 7")+
  theme_minimal()+
  theme(plot.title = element_text(face = "bold", hjust = 0.5))

#speechiness in explicitt music
ggplot(edadf2) +
  aes(x = "", y = speechiness, fill = explicit_fac) +
  geom_boxplot() +
  scale_fill_manual(
    values = c(`Non-Explicit` = "#440154",
    Explicit = "#FDE725")
  ) +
  theme_minimal() +
  labs(
    title = "Speechiness in explicit and non explicit songs",
    
    caption = "Fig 8")+
  theme_minimal()+
  theme(plot.title = element_text(face = "bold", hjust = 0.5))

```

### III.Other characteristics

A few variables such as key and time signature are part of this dataset, although they were not chosen as the predictors. Most of the remaining variables in this dataset pertain to the artist name, the song title, the modalities and key of a song, the duration and the release dates. Nonetheless, some variables were still relatively interesting in terms of prediction. To illustrate, one could predict the scale of a song based on the popularity, in addition to other predictors. However, some were not chosen because they were differently coded, such as time signature, which has an extremely limited set of plausible values (lacks signatures like 6/8). In contrast, other variables offered little or irrelevant information, such as Liveness. For example, it parametrizes a song's performance as a live or studio quality recording, and, given that the songs that play on the radio tend to be studio songs, we opted to not use this variable as a predictor.

### IV. Potential Challenges

1. The categorical response factor, “explicit”, does not have even distribution over years. Namely, songs in most recent years are generally in explicit form, meaning that the training for inexplicit songs could be limited by fewer explicit data points.

2. The predictors we chose are mostly numeric, music characteristics, such as tempo and acousticsness. However, “artists” might be a key to motivating people to listen to the music, which is not addressed in the research. After all, the general public might not be too sensitive to the musical characteristics, but care more about what and whom others are listening to.

3. Based on the correlation matrix, we discovered potential collinearity between energy and acousticness, which has a correlation efficient of almost 1.

\newpage

### Appendix

**Correlation Matrix**

```{r echo=FALSE, message = FALSE}
cordf1 = cor(df1)
corrplot(cordf1, method = 'color', order = 'alphabet')
```

```{r, results = "asis", message=FALSE, warning=FALSE, echo=FALSE}
Popularity_group <- c("Popularity group 1", "Popularity group 2", "Popularity group 3", "Popularity group 4","Popularity group 4")
Criteria <- c("popularity <= 20", "popularity <= 40", "popularity <= 60", "popularity <= 80", "popularity <= 100")
Popularity <- data.frame(Popularity_group, Criteria)
knitr::kable(Popularity,"pipe", align = c("c","c"), caption = "Popularity Grouping")
```

#### Bibliography (Citations)

Androids (2017, October 13). An Idiot’s Guide to EDM Genres. Retrieved October 20, 2022, from https://www.complex.com/music/an-idiots-guide-to-edm-genres/

Burchell, C. (2019, May 27). 10 Tips for Making Your First Trap Beat. Inverse. Retrieved October 20, 2022, from https://flypaper.soundfly.com/produce/10-tips-for-making-your-first-trap-beat/#

Edwords, E. (n.d.). Rap Song Structure Is TOO Important To Ignore. Retrieved October 20, 2022, from https://rhymemakers.com/rap-song-structure/

Leviatan, Y. (2017, July 27). Making Music: The 6 Stages of Music Production. Waves. Retrieved October 20, 2022, from https://www.waves.com/six-stages-of-music-production

Spotify (2022). Spotify Web API Reference | Spotify for Developers. https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features

Tayag, Y. (2017, May 17). Expert on Male Psychology Explains How Pop Got Sexually Explicit. Retrieved October 20, 2022, from https://www.inverse.com/article/31842-pop-music-sexually-explicit-lyrics-rap-hip-hop

Yamac. (2016). Spotify Dataset 1921-2020, 600k+ Tracks. Spotify. Retrieved October 3, 2022, from https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks
