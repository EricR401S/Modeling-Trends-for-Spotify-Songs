---
title: "IDS 702 Team Black Project"
author: "Emma Wang, Pragya Raghuvanshi, Lorna Aine, Eric Rios Soderman"
date: "2022-10-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:


Load the data

```{r subset}
#read data
#df <- read.csv("/Users/pr158admin/Modeling-Trends-for-Spotify-Songs/archive/tracks.csv")
df <- read.csv("https://github.com/EricR401S/Modeling-Trends-for-Spotify-Songs/raw/main/archive/tracks.csv")
```

Cleaning

# Two columns of interest : Name of artist (if one wanted to highlight certain summary statistics), duration conversion (get minutes), the rest is perfect on its own. 


```{r}

# Confirming the data types of the columns
sapply(df, class)

# Removing the brackets from the names of the artists
# This will facilitate summary statistics

df$artists<-gsub("]","",as.character(df$artists))
df$artists<-gsub("^.","",as.character(df$artists))

# New minute variable for our own use to simplify interpretation

df$duration_minutes <- df$duration_ms/(1000*60)


# Confirming that there are no missing data, except the artist name column

colSums(is.na(df))

# change "explicit" into binary factor
df$explicit_fac <- factor(df$explicit,
                         levels=c(0,1),
                         labels=c('Non-Explicit','Explicit'))

# make Date readable to R
df$release_date <- as.Date(df$release_date, "%Y-%m-%d")


# According to variable definitions, speechiness levels above 0.66 are speech tracks such as podcasts and poetries.
# They will be removed.


df0 <- df[df$speechiness <= 0.66,]
nrow(df) - nrow(df0) #22,598 records of speech tracks

# Examining records with a value of 0 for tempo
# A total of 328 records with 0 tempo were found, and most were tracks of rain sounds and introductions. 
# Some were, unfortunately, real songs.

sum(df0$tempo==0)

# 148 of those records are from the 2010s decade, our area of interest. 
tempo_0_subset <- df0[df0$tempo == 0,]
tempo_0_subset_2010s <- tempo_0_subset[grep('201[0-9].*', tempo_0_subset$release_date),]
nrow(tempo_0_subset_2010s)

# Removing records with a value of 0 for tempo

df0 <- df0[df0$tempo != 0,]


```

```{r subset}
#subset data
#subset <- df0[grepl('201[0-9].*', df$release_date),] ------- Decades Version
subset <- df0[grep('2010.*', df$release_date),]
```
## I.Data Overview 


Provide the chief characteristics of your data, including sample size, number of
variables, and source. Include your research questions here.


Description of Dataset




Definitions of Main Variables of interest

*Popularity (DV1)* is calculated by an algorithm that is based on how many times a track has been played and how recent those plays were. This is the response variable of interest for research question 1 (Spotify, 2022).

*Explicitness (DV2)* is whether a song contains inappropriate words such as curse words and other words that are deemed socially unacceptable to play in some public settings, especially settings with children. 1 is the value identifying a song as explicit, while 0 implies that a song is non-explicit. This is the dependent variable for the second research question (Spotify, 2022).

*acousticness* is a confidence measure from 0.0 to 1.0 of how much of the track is composed with acoustic instruments. 1.0 represents high confidence the track is acoustic (Spotify, 2022).

*danceability* is a rating of a track's suitability for dancing. This metric is based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable (Spotify, 2022).

*energy* is a perceptual measure of intensity and activity. Energetic tracks typically feel fast, loud, and noisy (Spotify, 2022).

*instrumentation* pertains to whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumentals in this context, while Rap or spoken word tracks are considered "vocal". As the instrumentalness value approaches 1.0, there is a greater likelihood that the track contains no vocal content. In addition, values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0 (Spotify, 2022).

*tempo* refers to the overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, which derives directly from the average beat duration (Spotify, 2022).

*loudness* measures the overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological association of physical strength (amplitude). Lastly, the values typically range between -60 and 0 db (Spotify, 2022).

*speechiness* detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks (Spotify, 2022).

Definitions from Spotify: Eric Biliography link[https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features]

## II. Primary relationship of interest

EDA (graphs)



Relationship to Research Questions

In the research, we have two main Research Questions:
RQ1.	What are the musical attributes that gauged the popularity of songs in the 2010s? 
*Dependent Variable (continuous) = popularity*
*Independent Variables = acousticness, danceability, energy, instrumentation, tempo, loudness, and speechiness* 
In RQ1, we aim to "infer" what features of music could better measure the popularity.
 
RQ2.	To what extent can the musicality of a song predict whether a song will be explicit or non-explicit? 

*Dependent Variable (categorical) = Explicitness*
*Independent Variables = danceability, energy, speechiness, and tempo* 
In RQ2, we aim to "predict" whether the song is explicit or not by the four features of music: dancebility, energy, speechiness, tempo.



Relationships within data

```{r}
library(psych)

RQ1_relation <- c("popularity", "acousticness", "danceability", "energy", "instrumentalness", "tempo", "loudness", "speechiness")
df1 = subset[RQ1_relation]

pairs.panels(df1)
```

```{r}
RQ2_relation <- c("explicit", "danceability", "energy", "speechiness","tempo")
df2 = subset[RQ2_relation]

pairs.panels(df2)
```
## III.Other characteristics

## IV. Potential Challenges




## V. Bibliography (Citations)

Spotify (2022). Spotify Web API Reference | Spotify for Developers. https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features

